<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
<title>LocalLLM by Actalithic</title>
<link rel="icon" type="image/png" href="https://i.ibb.co/KxCDDsc7/logoico.png">
<link href="https://fonts.googleapis.com/css2?family=DM+Mono:wght@300;400;500&family=Syne:wght@400;700;800&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/icon?family=Material+Icons+Round" rel="stylesheet">
<link rel="stylesheet" href="css/style.css">
<!-- Apply theme before paint to avoid flash -->
<script>
(function(){
  const s=localStorage.getItem('llm-theme');
  document.documentElement.setAttribute('data-theme',s||(window.matchMedia('(prefers-color-scheme: dark)').matches?'dark':'light'));
})();
</script>
</head>
<body>

<!-- ── MODEL MANAGER MODAL ── -->
<div class="modal-overlay" id="modelModal" onclick="closeModalOutside(event)">
  <div class="modal">
    <div class="modal-head">
      <div class="modal-title">Model Manager</div>
      <button class="modal-close" onclick="closeModal()"><span class="material-icons-round">close</span></button>
    </div>
    <div class="modal-body" id="modalBody"></div>
    <div class="modal-foot">Switch or remove models here. To download a new model, return to the home screen.</div>
  </div>
</div>

<!-- ── MODEL INFO POPUP (URL) ── -->
<div class="modal-overlay" id="modelInfoModal" onclick="closeModelInfoOutside(event)">
  <div class="modal">
    <div class="modal-head">
      <div class="modal-title">Model Source</div>
      <button class="modal-close" onclick="closeModelInfoModal()"><span class="material-icons-round">close</span></button>
    </div>
    <div class="modal-body">
      <div class="modal-note" style="flex-direction:column;gap:.35rem">
        <div>
          <div class="model-info-popup-label">Active model</div>
          <div class="model-info-popup-name" id="modelInfoName"></div>
          <div class="model-info-popup-label">Downloaded from</div>
          <a class="model-info-popup-url" id="modelInfoUrl" target="_blank" rel="noopener"></a>
        </div>
        <div style="font-size:.65rem;color:var(--muted);margin-top:.3rem">Models are quantized and served via MLC AI / Hugging Face. They are cached in your browser after the first download.</div>
      </div>
    </div>
  </div>
</div>

<!-- ── HEADER ── -->
<header>
  <div class="header-brand">
    <img id="headerLogo" class="logo-img" src="https://i.ibb.co/mV4rQV7B/Chat-GPT-Image-18-Feb-2026-08-42-07.png" alt="LocalLLM by Actalithic">
  </div>
  <div class="header-right">
    <!-- Info button — shown only after a model loads -->
    <button id="modelInfoBtn" onclick="openModelInfo()" title="View model source URL">
      <span class="material-icons-round">info</span>
    </button>
    <a class="icon-btn bsky" href="https://bsky.app/profile/actalithic.bsky.social" target="_blank" rel="noopener" title="Actalithic on Bluesky">
      <svg viewBox="0 0 600 530" xmlns="http://www.w3.org/2000/svg"><path d="m135.72 44.03c66.496 49.921 138.02 151.14 164.28 205.46 26.262-54.316 97.782-155.54 164.28-205.46 47.98-36.021 125.72-63.892 125.72 24.795 0 17.712-10.155 148.79-16.111 170.07-20.703 73.984-96.144 92.854-163.25 81.433 117.3 19.964 147.14 86.092 82.697 152.22-122.39 125.59-175.91-31.511-189.63-71.766-2.514-7.3797-3.6904-10.832-3.7077-7.8964-0.0174-2.9357-1.1937 0.51669-3.7077 7.8964-13.714 40.255-67.233 197.36-189.63 71.766-64.444-66.128-34.605-132.26 82.697-152.22-67.108 11.421-142.55-7.4491-163.25-81.433-5.9562-21.282-16.111-152.36-16.111-170.07 0-88.687 77.742-60.816 125.72-24.795z" fill="currentColor"/></svg>
    </a>
    <button class="icon-btn" id="themeToggle" onclick="toggleTheme()" title="Toggle dark/light mode">
      <span class="material-icons-round" id="themeIcon">dark_mode</span>
    </button>
    <div class="model-badge" id="modelBadge" onclick="openModal()" title="Manage models">
      <span class="material-icons-round">memory</span>
      <span id="modelBadgeText">no model loaded</span>
    </div>
  </div>
</header>

<div class="offline-banner" id="offlineBanner">
  <span class="material-icons-round">wifi_off</span>
  Offline — app running from cache. Inference works normally; new model downloads unavailable.
</div>

<!-- ── LOAD SCREEN ── -->
<div id="loadScreen">
  <div class="load-ring" id="spinner"></div>

  <div class="load-hero">
    <div class="load-title">100% local. Zero server. Zero API.</div>
    <div class="load-sub" id="loadSub">
      Runs entirely in your browser via WebGPU. First download is cached permanently — subsequent loads are instant.
    </div>
  </div>

  <div class="progress-wrap" id="progressWrap">
    <div class="progress-track"><div class="progress-fill" id="progressFill"></div></div>
    <div class="progress-row">
      <div class="progress-status" id="progressStatus">Initializing…</div>
      <div class="progress-label" id="progressLabel">0%</div>
    </div>
  </div>

  <div class="disclaimer-note">
    <span class="material-icons-round">info</span>
    <span>Models below are developed by third-party organizations — Meta, Microsoft, Mistral AI, Alibaba Cloud, and DeepSeek. Actalithic does not own, train, or take responsibility for these models or their outputs. Downloads are sourced externally via MLC AI and Hugging Face.</span>
  </div>

  <div class="model-select-card" id="modelSelectWrap">
    <select id="modelSelect" onchange="updateModelInfo()">
      <optgroup label="Fast">
        <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC">Llama 3.2 1B — Meta · 0.8 GB</option>
        <option value="Llama-3.2-3B-Instruct-q4f16_1-MLC" selected>Llama 3.2 3B — Meta · 2 GB</option>
      </optgroup>
      <optgroup label="Smart">
        <option value="Phi-3.5-mini-instruct-q4f16_1-MLC">Phi 3.5 Mini — Microsoft · 2.2 GB</option>
        <option value="Phi-4-mini-instruct-q4f16_1-MLC">Phi 4 Mini — Microsoft · 3 GB</option>
        <option value="Mistral-7B-Instruct-v0.3-q4f16_1-MLC">Mistral 7B — Mistral AI · 4 GB</option>
      </optgroup>
      <optgroup label="Powerful">
        <option value="Llama-3.1-8B-Instruct-q4f16_1-MLC">Llama 3.1 8B — Meta · 5 GB</option>
        <option value="Qwen2.5-7B-Instruct-q4f16_1-MLC">Qwen 2.5 7B — Alibaba · 4.5 GB</option>
        <option value="Qwen2.5-Coder-7B-Instruct-q4f16_1-MLC">Qwen 2.5 Coder 7B — coding · 4.5 GB</option>
        <option value="DeepSeek-R1-Distill-Llama-8B-q4f16_1-MLC">DeepSeek R1 8B — reasoning · 5 GB</option>
        <option value="Llama-3.3-70B-Instruct-q2f16_1-MLC">Llama 3.3 70B — Meta · 35 GB</option>
      </optgroup>
    </select>
    <div class="model-info-row" id="modelInfoRow"></div>
  </div>

  <!-- Speed reference table — updates dynamically per selected model -->
  <div class="speed-table">
    <div class="speed-table-head">Expected speed by device (tokens per second)</div>
    <div class="speed-row">
      <div class="speed-device">Dedicated GPU (RTX 3060+)</div>
      <div class="speed-val" id="speed-dedicated">—</div>
    </div>
    <div class="speed-row">
      <div class="speed-device">Steam Deck (RDNA2 iGPU)</div>
      <div class="speed-val" id="speed-steamdeck">—</div>
    </div>
    <div class="speed-row">
      <div class="speed-device">Laptop with integrated GPU</div>
      <div class="speed-val" id="speed-laptop">—</div>
    </div>
    <div class="speed-row">
      <div class="speed-device">Nothing Phone 3a (Snapdragon)</div>
      <div class="speed-val" id="speed-phone">—</div>
    </div>
    <div class="speed-row">
      <div class="speed-device">CPU / WASM fallback</div>
      <div class="speed-val" id="speed-cpu">—</div>
    </div>
    <div class="speed-row">
      <div class="speed-device">ActalithicCore (GPU+CPU hybrid)</div>
      <div class="speed-val" id="speed-core">—</div>
    </div>
  </div>

  <!-- Engine toggles -->
  <div class="toggle-section">
    <div class="toggle-section-label">Engine options</div>

    <div class="exp-row">
      <div class="exp-label">
        <div class="exp-label-title">
          ActalithicCore
          <span class="core-badge">Actalithic</span>
        </div>
        <div class="exp-label-sub">Splits model layers across GPU and CPU simultaneously. Lets you run larger models than your GPU VRAM alone allows, without sacrificing GPU speed. Recommended for devices with limited VRAM but enough system RAM.</div>
      </div>
      <label class="toggle"><input type="checkbox" id="coreToggle"><span class="toggle-slider"></span></label>
    </div>

    <div class="exp-row">
      <div class="exp-label">
        <div class="exp-label-title">
          CPU / WASM fallback
          <span class="exp-badge">Experimental</span>
        </div>
        <div class="exp-label-sub">Use if WebGPU is unavailable or your GPU has insufficient VRAM. Runs on CPU only via WebAssembly. Expect significantly slower inference — about 1–3 tok/s.</div>
      </div>
      <label class="toggle"><input type="checkbox" id="cpuToggle"><span class="toggle-slider"></span></label>
    </div>
  </div>

  <button class="load-btn" id="loadBtn" onclick="loadModel()">
    <span class="material-icons-round">download</span>
    Download &amp; Load
  </button>
</div>

<!-- ── CHAT SCREEN ── -->
<div id="chatScreen">
  <div class="messages" id="messages"></div>
  <div class="bottom-area">
    <!-- System prompt is hidden from UI; managed internally -->
    <div class="input-bar">
      <textarea id="msgInput" placeholder="Message…" rows="1" onkeydown="handleKey(event)" oninput="autoResize(this)"></textarea>
      <button class="send-btn" id="sendBtn" onclick="sendMessage()">
        <span class="material-icons-round">send</span>
      </button>
    </div>
    <div class="info-bar">Actalithic LocalLLM &nbsp;&middot;&nbsp; Running locally &nbsp;&middot;&nbsp; <span id="tokenSpeed"></span></div>
  </div>
</div>

<!-- Theme + SW (plain script, runs immediately) -->
<script src="js/theme.js" type="module"></script>
<!-- Main app logic (ES module) -->
<script src="js/app.js" type="module"></script>

</body>
</html>
